# Gen-AI-Image-Caption-Generator

# ğŸ–¼ï¸ Image Caption Generator with BLIP

This project uses the [Salesforce BLIP (Bootstrapped Language Image Pretraining)](https://huggingface.co/Salesforce/blip-image-captioning-base) model to generate image captions and descriptive narratives from any image. It also includes an option to produce "corrupted" captions by injecting random words for creative tasks or adversarial testing.

---

## ğŸ“Œ Features

* âœ… Generates image captions using BLIP pre-trained model
* ğŸ§  Creates detailed, beam-search-based image descriptions
* ğŸ”€ Adds random corruption to captions for robustness/experimentation
* ğŸ“· Visual display with caption or description using `matplotlib`

---

## ğŸ§° Technologies Used

* Python ğŸ
* Hugging Face Transformers ğŸ¤—
* PyTorch ğŸ”¥
* Matplotlib ğŸ“Š
* PIL (Pillow) ğŸ–¼ï¸
* torchvision

---

## ğŸ“¦ Installation

1. **Clone this repository**:

   ```bash
   git clone https://github.com/your-username/image-caption-generator.git
   cd image-caption-generator
   ```

2. **Install the required dependencies**:

   ```bash
   pip install -r requirements.txt
   ```

   You can create a `requirements.txt` with:

   ```txt
   torch
   torchvision
   transformers
   matplotlib
   Pillow
   ```

---

## ğŸš€ Usage

### ğŸ”¹ Generate Basic Caption

```python
caption = generate_caption(image_path)
display_image_with_caption(image_path, caption)
```

### ğŸ”¹ Generate Corrupted Caption

```python
caption = existing_generate_caption(image_path)
display_image_with_caption(image_path, caption)
```

### ğŸ”¹ Generate Detailed Description

```python
description = generate_detailed_description(image_path)
display_image_with_description(image_path, description)
```

---

## ğŸ“‚ Example Output

| Input Image                             | Caption/Description                                            |
| --------------------------------------- | -------------------------------------------------------------- |
| ![Sample](./sample_outputs/sample1.jpg) | *"A plate of delicious Indian shrikhand served with saffron."* |

---

## ğŸ§  Model

The model used is:

```text
Salesforce/blip-image-captioning-base
```

You can explore it on Hugging Face:
ğŸ‘‰ [https://huggingface.co/Salesforce/blip-image-captioning-base](https://huggingface.co/Salesforce/blip-image-captioning-base)

---

## ğŸ“Œ Folder Structure (Optional Suggestion)

```text
.
â”œâ”€â”€ blip_captioning.py
â”œâ”€â”€ sample_outputs/
â”‚   â””â”€â”€ sample1.jpg
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```




